<HTML>
<HEAD>
<title>Understanding the Linux Kernel: Chapter 10: Process Scheduling</title>
</head>

<BODY BGCOLOR="#FFFFFF" TEXT="#000000" link="#990000" vlink="#0000CC">
<table BORDER="0" CELLPADDING="0" CELLSPACING="0" width="90%">
<tr>
<td colspan=2>
<IMG WIDTH="515" height="37" ALIGN="BOTTOM"
 ALT="Search the Catalog" BORDER="0" 
 USEMAP="#catalog_header_buttons" ISMAP
 SRC="/graphics_new/catalog_header_buttons.gif">
<MAP Name="catalog_header_buttons">
<aREA Shape="Rect" coords = "407,17,512,32"  href="/catalog/search.html">
<aREA Shape="Rect" coords = "431,3,512,18"  href="/catalog/prdindex.html">
</MAP>
</td>
</tr>
<tr>
<td width="25%" valign="TOP">
<A HREF="/catalog/linuxkernel/">
<img hspace=10 vspace=10 src="/catalog/covers/linuxkernel.s.gif" 
alt="Understanding the Linux Kernel" align=left valign=top border=0>
</a>
</td>
<td height="105" valign="TOP">
<br>
<H2>Understanding the Linux Kernel</H2>
<font size="-1">
By Daniel P. Bovet &amp; Marco Cesati</A><BR>
October 2000<BR>
0-596-00002-2, Order Number: 0022<br>
704 pages, $39.95
</font>
</td>
</tr>
</table>
<hr size=1 noshade>
<!--sample chapter begins -->

<blockquote>

<h2 class="ChapterTitle">Chapter 10
<br>
<A NAME="36392"></a>Process Scheduling</h2>


<P CLASS="Body">Like any time-sharing system, Linux achieves the magical effect of an apparent simultaneous execution of multiple processes by switching from one process to another in a very short time frame. Process switch itself was discussed in <EM CLASS="EmphasisRoman">Chapter 3, </em><CITE CLASS="Citation">Processes</cite>; this chapter deals with <EM CLASS="Emphasis">scheduling</em>, which is concerned with when to switch and which process to choose.</p>


<P CLASS="Body">The chapter consists of three parts. The section "<A HREF="ch10.html#94726" CLASS="XRef">Scheduling Policy</a>&quot; introduces the choices made by Linux to schedule processes in the abstract. The section "<A HREF="ch10.html#85347" CLASS="XRef">The Scheduling Algorithm</a>&quot; discusses the data structures used to implement scheduling and the corresponding algorithm. Finally, the section "<A HREF="ch10.html#77170" CLASS="XRef">System Calls Related to Scheduling</a>&quot; describes the system calls that affect process scheduling.</p>


<H2 CLASS="HeadA"><A NAME="94726"></a>Scheduling Policy</h2>


<P CLASS="Body">The scheduling algorithm of traditional Unix operating systems must fulfill several conflicting objectives: fast process response time, good throughput for background jobs, avoidance of process starvation, reconciliation of the needs of low- and high-priority processes, and so on. The set of rules used to determine when and how selecting a new process to run is called <EM CLASS="Emphasis">scheduling policy</em>.</p>


<P CLASS="Body">Linux scheduling is based on the <EM CLASS="Emphasis">time-sharing</em> technique already introduced in the section &quot;CPU's Time Sharing&quot; in <EM CLASS="EmphasisRoman">Chapter 5, </em><CITE CLASS="Citation">Timing Measurements</cite>: several processes are allowed to run &quot;concurrently,&quot; which means that the CPU time is roughly divided into &quot;slices,&quot; one for each runnable process.<A HREF="#footnote-1" TITLE="Footnote" CLASS="footnote">[1]</a> Of course, a single processor can run only one process at any given instant. If a currently running process is not terminated when its time slice or <EM CLASS="Emphasis">quantum</em> expires, a process switch may take place. Time-sharing relies on timer interrupts and is thus transparent to processes. No additional code needs to be inserted in the programs in order to ensure CPU time-sharing.</p>


<P CLASS="Body">The scheduling policy is also based on ranking processes according to their priority. Complicated algorithms are sometimes used to derive the current priority of a process, but the end result is the same: each process is associated with a value that denotes how appropriate it is to be assigned to the CPU.</p>


<P CLASS="Body">In Linux, process priority is dynamic. The scheduler keeps track of what processes are doing and adjusts their priorities periodically; in this way, processes that have been denied the use of the CPU for a long time interval are boosted by dynamically increasing their priority. Correspondingly, processes running for a long time are penalized by decreasing their priority.</p>


<P CLASS="Body">When speaking about scheduling, processes are traditionally classified as &quot;I/O-bound&quot; or &quot;CPU-bound.&quot; The former make heavy use of I/O devices and spend much time waiting for I/O operations to complete; the latter are number-crunching applications that require a lot of CPU time.</p>


<P CLASS="Body">An alternative classification distinguishes three classes of processes:</p>

<DL>
<DT CLASS="ListVariableTerm"><EM CLASS="Emphasis">Interactive processes</em> </dt>
<DD CLASS="ListVariable">These interact constantly with their users, and therefore spend a lot of time waiting for keypresses and mouse operations. When input is received, the process must be woken up quickly, or the user will find the system to be unresponsive. Typically, the average delay must fall between 50 and 150 ms. The variance of such delay must also be bounded, or the user will find the system to be erratic. Typical interactive programs are command shells, text editors, and graphical applications.</dd>
<p>
<DT CLASS="ListVariableTerm"><EM CLASS="Emphasis">Batch processes</em> </dt>
<DD CLASS="ListVariable">These do not need user interaction, and hence they often run in the background. Since such processes do not need to be very responsive, they are often penalized by the scheduler. Typical batch programs are programming language compilers, database search engines, and scientific computations.</dd>
<p>
<DT CLASS="ListVariableTerm"><EM CLASS="Emphasis">Real-time processes</em> </dt>
<DD CLASS="ListVariable">These have very strong scheduling requirements. Such processes should never be blocked by lower-priority processes, they should have a short response time and, most important, such response time should have a minimum variance. Typical real-time programs are video and sound applications, robot controllers, and programs that collect data from physical sensors.</dd>
<p>
</dl>

<P CLASS="Body">The two classifications we just offered are somewhat independent. For instance, a batch process can be either I/O-bound (e.g., a database server) or CPU-bound (e.g., an image-rendering program). While in Linux real-time programs are explicitly recognized as such by the scheduling algorithm, there is no way to distinguish between interactive and batch programs. In order to offer a good response time to interactive applications, Linux (like all Unix kernels) implicitly favors I/O-bound processes over CPU-bound ones.</p>


<P CLASS="Body">Programmers may change the scheduling parameters by means of the system calls illustrated in <A HREF="ch10.html#51998" CLASS="XRef">Table 10-1</a>. More details will be given in the section "<A HREF="ch10.html#77170" CLASS="XRef">System Calls Related to Scheduling</a>.&quot;</p>

<TABLE border=1>
<CAPTION>
<B class="TableLabel"><a name="51998">Table 10-1:</a></b> 
<B class="TableTitle">System Calls Related to Scheduling </b> 
</caption>
<TR>
<TH ROWSPAN="1" COLSPAN="1">
<P CLASS="CellHeading">System Call</p>

</th>
<TH ROWSPAN="1" COLSPAN="1">
<P CLASS="CellHeading">Description</p>

</th>
</tr>
<TR>
<TD ROWSPAN="1" COLSPAN="1">
<P CLASS="CellBody"><CODE CLASS="Literal">nice(  )</code></p>

</td>
<TD ROWSPAN="1" COLSPAN="1">
<P CLASS="CellBody">Change the priority of a conventional process.</p>

</td>
</tr>
<TR>
<TD ROWSPAN="1" COLSPAN="1">
<P CLASS="CellBody"><CODE CLASS="Literal">getpriority(  )</code></p>

</td>
<TD ROWSPAN="1" COLSPAN="1">
<P CLASS="CellBody">Get the maximum priority of a group of conventional 
<BR>

processes.</p>

</td>
</tr>
<TR>
<TD ROWSPAN="1" COLSPAN="1">
<P CLASS="CellBody"><CODE CLASS="Literal">setpriority(  )</code></p>

</td>
<TD ROWSPAN="1" COLSPAN="1">
<P CLASS="CellBody">Set the priority of a group of conventional processes.</p>

</td>
</tr>
<TR>
<TD ROWSPAN="1" COLSPAN="1">
<P CLASS="CellBody"><CODE CLASS="Literal">sched_getscheduler(  )</code></p>

</td>
<TD ROWSPAN="1" COLSPAN="1">
<P CLASS="CellBody">Get the scheduling policy of a process.</p>

</td>
</tr>
<TR>
<TD ROWSPAN="1" COLSPAN="1">
<P CLASS="CellBody"><CODE CLASS="Literal">sched_setscheduler(  )</code></p>

</td>
<TD ROWSPAN="1" COLSPAN="1">
<P CLASS="CellBody">Set the scheduling policy and priority of a process.</p>

</td>
</tr>
<TR>
<TD ROWSPAN="1" COLSPAN="1">
<P CLASS="CellBody"><CODE CLASS="Literal">sched_getparam(  )</code></p>

</td>
<TD ROWSPAN="1" COLSPAN="1">
<P CLASS="CellBody">Get the scheduling priority of a process.</p>

</td>
</tr>
<TR>
<TD ROWSPAN="1" COLSPAN="1">
<P CLASS="CellBody"><CODE CLASS="Literal">sched_setparam(  )</code></p>

</td>
<TD ROWSPAN="1" COLSPAN="1">
<P CLASS="CellBody">Set the priority of a process.</p>

</td>
</tr>
<TR>
<TD ROWSPAN="1" COLSPAN="1">
<P CLASS="CellBody"><CODE CLASS="Literal">sched_yield(  )</code></p>

</td>
<TD ROWSPAN="1" COLSPAN="1">
<P CLASS="CellBody">Relinquish the processor voluntarily without blocking.</p>

</td>
</tr>
<TR>
<TD ROWSPAN="1" COLSPAN="1">
<P CLASS="CellBody"><CODE CLASS="Literal">sched_get_ priority_min(  )</code></p>

</td>
<TD ROWSPAN="1" COLSPAN="1">
<P CLASS="CellBody">Get the minimum priority value for a policy.</p>

</td>
</tr>
<TR>
<TD ROWSPAN="1" COLSPAN="1">
<P CLASS="CellBody"><CODE CLASS="Literal">sched_get_ priority_max(  )</code></p>

</td>
<TD ROWSPAN="1" COLSPAN="1">
<P CLASS="CellBody">Get the maximum priority value for a policy.</p>

</td>
</tr>
<TR>
<TD ROWSPAN="1" COLSPAN="1">
<P CLASS="CellBody"><CODE CLASS="Literal">sched_rr_get_interval(  )</code></p>

</td>
<TD ROWSPAN="1" COLSPAN="1">
<P CLASS="CellBody">Get the time quantum value for the Round Robin policy.</p>

</td>
</tr>
</table>

<P CLASS="Body">Most system calls shown in the table apply to real-time processes, thus allowing users to develop real-time applications. However, Linux does not support the most demanding real-time applications because its kernel is nonpreemptive (see the later section "<A HREF="ch10.html#39073" CLASS="XRef">Performance of the Scheduling Algorithm</a>&quot;).</p>


<H3 CLASS="HeadB"><A NAME="23782"></a>Process Preemption</h3>


<P CLASS="Body">As mentioned in the first chapter, Linux processes are <EM CLASS="Emphasis">preemptive</em>. If a process enters the <CODE CLASS="Literal">TASK_RUNNING</code> state, the kernel checks whether its dynamic priority is greater than the priority of the currently running process. If it is, the execution of <CODE CLASS="Literal">current</code> is interrupted and the scheduler is invoked to select another process to run (usually the process that just became runnable). Of course, a process may also be preempted when its time quantum expires. As mentioned in the section &quot;CPU's Time Sharing&quot; in Chapter 5, when this occurs, the <CODE CLASS="Literal">need_resched</code> field of the current process is set, so the scheduler is invoked when the timer interrupt handler terminates.</p>


<P CLASS="Body">For instance, let us consider a scenario in which only two programs--a text editor and a compiler--are being executed. The text editor is an interactive program, therefore it has a higher dynamic priority than the compiler. Nevertheless, it is often suspended, since the user alternates between pauses for think time and data entry; moreover, the average delay between two keypresses is relatively long. However, as soon as the user presses a key, an interrupt is raised, and the kernel wakes up the text editor process. The kernel also determines that the dynamic priority of the editor is higher than the priority of <CODE CLASS="Literal">current</code>, the currently running process (that is, the compiler), and hence it sets the <CODE CLASS="Literal">need_resched</code> field of this process, thus forcing the scheduler to be activated when the kernel finishes handling the interrupt. The scheduler selects the editor and performs a task switch; as a result, the execution of the editor is resumed very quickly and the character typed by the user is echoed to the screen. When the character has been processed, the text editor process suspends itself waiting for another keypress, and the compiler process can resume its execution.</p>


<P CLASS="Body">Be aware that a preempted process is not suspended, since it remains in the <CODE CLASS="Literal">TASK_RUNNING</code> state; it simply no longer uses the CPU.</p>


<P CLASS="Body">Some real-time operating systems feature preemptive kernels, which means that a process running in Kernel Mode can be interrupted after any instruction, just as it can in User Mode. The Linux kernel is not preemptive, which means that a process can be preempted only while running in User Mode; nonpreemptive kernel design is much simpler, since most synchronization problems involving the kernel data structures are easily avoided (see the section &quot;Nonpreemptability of Processes in Kernel Mode&quot; in <EM CLASS="EmphasisRoman">Chapter 11, </em><CITE CLASS="Citation">Kernel Synchronization</cite>).</p>


<H3 CLASS="HeadB">How Long Must a Quantum Last?</h3>


<P CLASS="Body">The quantum duration is critical for system performances: it should be neither too long nor too short.</p>


<P CLASS="Body">If the quantum duration is too short, the system overhead caused by task switches becomes excessively high. For instance, suppose that a task switch requires 10 milliseconds; if the quantum is also set to 10 milliseconds, then at least 50% of the CPU cycles will be dedicated to task switch.<A HREF="#footnote-2" TITLE="Footnote" CLASS="footnote">[2]</a> </p>


<P CLASS="Body">If the quantum duration is too long, processes no longer appear to be executed concurrently. For instance, let's suppose that the quantum is set to five seconds; each runnable process makes progress for about five seconds, but then it stops for a very long time (typically, five seconds times the number of runnable processes).</p>


<P CLASS="Body">It is often believed that a long quantum duration degrades the response time of interactive applications. This is usually false. As described in the section "<A HREF="ch10.html#23782" CLASS="XRef">Process Preemption</a>&quot; earlier in this chapter, interactive processes have a relatively high priority, therefore they quickly preempt the batch processes, no matter how long the quantum duration is.</p>


<P CLASS="Body">In some cases, a quantum duration that is too long degrades the responsiveness of the system. For instance, suppose that two users concurrently enter two commands at the respective shell prompts; one command is CPU-bound, while the other is an interactive application. Both shells fork a new process and delegate the execution of the user's command to it; moreover, suppose that such new processes have the same priority initially (Linux does not know in advance if an executed program is batch or interactive). Now, if the scheduler selects the CPU-bound process to run, the other process could wait for a whole time quantum before starting its execution. Therefore, if such duration is long, the system could appear to be unresponsive to the user that launched it.</p>


<P CLASS="Body">The choice of quantum duration is always a compromise. The rule of thumb adopted by Linux is: choose a duration as long as possible, while keeping good system response time.</p>


<H2 CLASS="HeadA"><A NAME="85347"></a>The Scheduling Algorithm</h2>


<P CLASS="Body">The Linux scheduling algorithm works by dividing the CPU time into <EM CLASS="Emphasis">epochs</em>. In a single epoch, every process has a specified time quantum whose duration is computed when the epoch begins. In general, different processes have different time quantum durations. The time quantum value is the maximum CPU time portion assigned to the process in that epoch. When a process has exhausted its time quantum, it is preempted and replaced by another runnable process. Of course, a process can be selected several times from the scheduler in the same epoch, as long as its quantum has not been exhausted--for instance, if it suspends itself to wait for I/O, it preserves some of its time quantum and can be selected again during the same epoch. The epoch ends when all runnable processes have exhausted their quantum; in this case, the scheduler algorithm recomputes the time-quantum durations of all processes and a new epoch begins.</p>


<P CLASS="Body">Each process has a <EM CLASS="Emphasis">base time quantum</em>: it is the time-quantum value assigned by the scheduler to the process if it has exhausted its quantum in the previous epoch. The users can change the base time quantum of their processes by using the <CODE CLASS="Literal">nice(  )</code> and <CODE CLASS="Literal">setpriority(  )</code> system calls (see the section "<A HREF="ch10.html#77170" CLASS="XRef">System Calls Related to Scheduling</a>&quot; later in this chapter). A new process always inherits the base time quantum of its parent.</p>


<P CLASS="Body">The <CODE CLASS="Literal">INIT_TASK</code> macro sets the value of the base time quantum of process 0 (<EM CLASS="Emphasis">swapper</em>) to <CODE CLASS="Literal">DEF_PRIORITY</code>; that macro is defined as follows: </p>

<PRE><CODE CLASS="Code">#define DEF_PRIORITY (20*HZ/100) </code>
</pre>

<P CLASS="Body">Since <CODE CLASS="Literal">HZ</code>, which denotes the frequency of timer interrupts, is set to 100 for IBM PCs (see the section &quot;Programmable Interval Timer&quot; in Chapter 5), the value of <CODE CLASS="Literal">DEF_PRIORITY</code> is 20 ticks, that is, about 210 ms.</p>


<P CLASS="Body">Users rarely change the base time quantum of their processes, so <CODE CLASS="Literal">DEF_PRIORITY</code> also denotes the base time quantum of most processes in the system.</p>


<P CLASS="Body">In order to select a process to run, the Linux scheduler must consider the priority of each process. Actually, there are two kinds of priority:</p>

<DL>
<DT CLASS="ListVariableTerm"><EM CLASS="Emphasis">Static priority</em> </dt>
<DD CLASS="ListVariable">This kind is assigned by the users to real-time processes and ranges from 1 to 99. It is never changed by the scheduler.</dd>
<p>
<DT CLASS="ListVariableTerm"><EM CLASS="Emphasis">Dynamic priority</em> </dt>
<DD CLASS="ListVariable">This kind applies only to conventional processes; it is essentially the sum of the base time quantum (which is therefore also called the <EM CLASS="Emphasis">base priority</em> of the process) and of the number of ticks of CPU time left to the process before its quantum expires in the current epoch.</dd>
<p>
</dl>

<P CLASS="Body">Of course, the static priority of a real-time process is always higher than the dynamic priority of a conventional one: the scheduler will start running conventional processes only when there is no real-time process in a <CODE CLASS="Literal">TASK_RUNNING</code> state.</p>


<H3 CLASS="HeadB">Data Structures Used by the Scheduler</h3>


<P CLASS="Body">We recall from the section &quot;Process Descriptor&quot; in Chapter 3 that the process list links together all process descriptors, while the runqueue list links together the process descriptors of all runnable processes--that is, of those in a <CODE CLASS="Literal">TASK_RUNNING</code> state. In both cases, the <CODE CLASS="Literal">init_task</code> process descriptor plays the role of list header.</p>


<P CLASS="Body">Each process descriptor includes several fields related to scheduling:</p>

<DL>
<DT CLASS="ListVariableTerm"><CODE CLASS="Literal">need_resched</code> </dt>
<DD CLASS="ListVariable">A flag checked by <CODE CLASS="Literal">ret_from_intr(  )</code> to decide whether to invoke the <CODE CLASS="Literal">schedule(  )</code> function (see the section &quot;The ret_ from_intr(  ) Function&quot; in <EM CLASS="EmphasisRoman">Chapter 4, </em><CITE CLASS="Citation">Interrupts and Exceptions</cite>).</dd>
<p>
<DT CLASS="ListVariableTerm"><CODE CLASS="Literal">policy</code> </dt>
<DD CLASS="ListVariable">The scheduling class. The values permitted are:</dd>
<p>
<DT CLASS="FM-ListVariableTerm"><CODE CLASS="Literal">SCHED_FIFO</code> </dt>
<DD CLASS="FM-ListVariable">A First-In, First-Out real-time process. When the scheduler assigns the CPU to the process, it leaves the process descriptor in its current position in the runqueue list. If no other higher-priority real-time process is runnable, the process will continue to use the CPU as long as it wishes, even if other real-time processes having the same priority are runnable.</dd>
<p>
<DT CLASS="FM-ListVariableTerm"><CODE CLASS="Literal">SCHED_RR</code> </dt>
<DD CLASS="FM-ListVariable">A Round Robin real-time process. When the scheduler assigns the CPU to the process, it puts the process descriptor at the end of the runqueue list. This policy ensures a fair assignment of CPU time to all <CODE CLASS="Literal">SCHED_RR</code> real-time processes that have the same priority.</dd>
<p>
<DT CLASS="FM-ListVariableTerm"><CODE CLASS="Literal">SCHED_OTHER</code> </dt>
<DD CLASS="FM-ListVariable">A conventional, time-shared process.</dd>
<p>
<DD CLASS="ListVariable-">The <CODE CLASS="Literal">policy</code> field also encodes a <CODE CLASS="Literal">SCHED_YIELD</code> binary flag. This flag is set when the process invokes the <CODE CLASS="Literal">sched_ yield(  )</code> system call (a way of voluntarily relinquishing the processor without the need to start an I/O operation or go to sleep; see the section "<A HREF="ch10.html#40766" CLASS="XRef">System Calls Related to Real-Time Processes</a>&quot;). The scheduler puts the process descriptor at the bottom of the runqueue list (see the later section "<A HREF="ch10.html#77170" CLASS="XRef">System Calls Related to Scheduling</a>&quot;).</dd>
<p>
<DT CLASS="ListVariableTerm"><CODE CLASS="Literal">rt_priority</code> </dt>
<DD CLASS="ListVariable">The static priority of a real-time process. Conventional processes do not make use of this field.</dd>
<p>
<DT CLASS="ListVariableTerm"><CODE CLASS="Literal">priority</code> </dt>
<DD CLASS="ListVariable">The base time quantum (or base priority) of the process.</dd>
<p>
<DT CLASS="ListVariableTerm"><CODE CLASS="Literal">counter</code> </dt>
<DD CLASS="ListVariable">The number of ticks of CPU time left to the process before its quantum expires; when a new epoch begins, this field contains the time-quantum duration of the process. Recall that the <CODE CLASS="Literal">update_process_times(  )</code> function decrements the <CODE CLASS="Literal">counter</code> field of the current process by 1 at every tick.</dd>
<p>
</dl>

<P CLASS="Body">When a new process is created, <CODE CLASS="Literal">do_fork(  )</code> sets the <CODE CLASS="Literal">counter</code> field of both <CODE CLASS="Literal">current</code> (the parent) and <CODE CLASS="Literal">p</code> (the child) processes in the following way: </p>

<PRE><CODE CLASS="Code">current-&gt;counter &gt;&gt;= 1; </code>
<CODE CLASS="Code">p-&gt;counter = current-&gt;counter; </code>
</pre>

<P CLASS="Body">In other words, the number of ticks left to the parent is split in two halves, one for the parent and one for the child. This is done to prevent users from getting an unlimited amount of CPU time by using the following method: the parent process creates a child process that runs the same code and then kills itself; by properly adjusting the creation rate, the child process would always get a fresh quantum before the quantum of its parent expires. This programming trick does not work since the kernel does not reward forks. Similarly, a user cannot hog an unfair share of the processor by starting lots of background processes in a shell or by opening a lot of windows on a graphical desktop. More generally speaking, a process cannot hog resources (unless it has privileges to give itself a real-time policy) by forking multiple descendents.</p>


<P CLASS="Body">Notice that the <CODE CLASS="Literal">priority</code> and <CODE CLASS="Literal">counter</code> fields play different roles for the various kinds of processes. For conventional processes, they are used both to implement time-sharing and to compute the process dynamic priority. For <CODE CLASS="Literal">SCHED_RR</code> real-time processes, they are used only to implement time-sharing. Finally, for <CODE CLASS="Literal">SCHED_FIFO</code> real-time processes, they are not used at all, because the scheduling algorithm regards the quantum duration as unlimited.</p>


<H3 CLASS="HeadB"><A NAME="57373"></a>The schedule(  ) Function</h3>


<P CLASS="Body"><CODE CLASS="Literal">schedule(  )</code> implements the scheduler. Its objective is to find a process in the runqueue list and then assign the CPU to it. It is invoked, directly or in a lazy way, by several kernel routines.</p>


<H4 CLASS="HeadC">Direct invocation</h4>


<P CLASS="Body">The scheduler is invoked directly when the <CODE CLASS="Literal">current</code> process must be blocked right away because the resource it needs is not available. In this case, the kernel routine that wants to block it proceeds as follows:</p>

<OL>
<LI CLASS="ListNumber">Inserts <CODE CLASS="Literal">current</code> in the proper wait queue</li>
<p>
<LI CLASS="ListNumber">Changes the state of <CODE CLASS="Literal">current</code> either to <CODE CLASS="Literal">TASK_INTERRUPTIBLE</code> or to <CODE CLASS="Literal">TASK_UNINTERRUPTI</code>BLE</li>
<p>
<LI CLASS="ListNumber">Invokes <CODE CLASS="Literal">schedule(  )</code></li>
<p>
<LI CLASS="ListNumber">Checks if the resource is available; if not, goes to step 2</li>
<p>
<LI CLASS="ListNumber">Once the resource is available, removes <CODE CLASS="Literal">current</code> from the wait queue</li>
<p>
</ol>

<P CLASS="Body">As can be seen, the kernel routine checks repeatedly whether the resource needed by the process is available; if not, it yields the CPU to some other process by invoking <CODE CLASS="Literal">schedule(  )</code>. Later, when the scheduler once again grants the CPU to the process, the availability of the resource is again checked.</p>


<P CLASS="Body">You may have noticed that these steps are similar to those performed by the <CODE CLASS="Literal">sleep_on(  )</code> and <CODE CLASS="Literal">interruptible_sleep_on(  )</code> functions described in the section &quot;Wait Queues&quot; in Chapter 3. However, the functions we discuss here immediately remove the process from the wait queue as soon as it is woken up.</p>


<P CLASS="Body">The scheduler is also directly invoked by many device drivers that execute long iterative tasks. At each iteration cycle, the driver checks the value of the <CODE CLASS="Literal">need_resched</code> field and, if necessary, invokes <CODE CLASS="Literal">schedule(  )</code> to voluntarily relinquish the CPU.</p>


<H4 CLASS="HeadC">Lazy invocation</h4>


<P CLASS="Body">The scheduler can also be invoked in a lazy way by setting the <CODE CLASS="Literal">need_resched</code> field of <CODE CLASS="Literal">current</code> to 1. Since a check on the value of this field is always made before resuming the execution of a User Mode process (see the section &quot;Returning from Interrupts and Exceptions&quot; in Chapter 4), <CODE CLASS="Literal">schedule(  )</code> will definitely be invoked at some close future time.</p>


<P CLASS="Body">Lazy invocation of the scheduler is performed in the following cases:</p>

<UL>
<LI CLASS="ListBullet">When <CODE CLASS="Literal">current</code> has used up its quantum of CPU time; this is done by the <CODE CLASS="Literal">update_process_times(  )</code> function.</li>
<p>
<LI CLASS="ListBullet">When a process is woken up and its priority is higher than that of the current process; this task is performed by the <CODE CLASS="Literal">reschedule_idle(  )</code> function, which is invoked by the <CODE CLASS="Literal">wake_up_process(  )</code> function (see the section &quot;Identifying a Process&quot; in Chapter 3): </li>
<p>
<CODE CLASS="Code">if (goodness(current, p) &gt; goodness(current, current)) </code>
<CODE CLASS="Code">    current-&gt;need_resched = 1; </code>

<P CLASS="Body">(The <CODE CLASS="Literal">goodness(  )</code> function will be described later in the section "<A HREF="ch10.html#20825" CLASS="XRef">How Good Is a Runnable Process?</a>&quot;)</p>

<LI CLASS="ListBullet">When a <CODE CLASS="Literal">sched_setscheduler(  )</code> or <CODE CLASS="Literal">sched_ yield(  )</code> system call is issued (see the section "<A HREF="ch10.html#77170" CLASS="XRef">System Calls Related to Scheduling</a>&quot; later in this chapter).</li>
<p>
</ul>

<H4 CLASS="HeadC">Actions performed by schedule(  )</h4>


<P CLASS="Body">Before actually scheduling a process, the <CODE CLASS="Literal">schedule(  )</code> function starts by running the functions left by other kernel control paths in various queues. The function invokes <CODE CLASS="Literal">run_task_queue(  )</code> on the <CODE CLASS="Literal">tq _scheduler</code> task queue. Linux puts a function in that task queue when it must defer its execution until the next <CODE CLASS="Literal">schedule(  )</code> invocation: </p>

<PRE><CODE CLASS="Code">run_task_queue(&amp;tq_scheduler); </code>
</pre>

<P CLASS="Body">The function then executes all active unmasked bottom halves. These are usually present to perform tasks requested by device drivers (see the section &quot;Bottom Half&quot; in Chapter 4): </p>

<PRE><CODE CLASS="Code">if (bh_active &amp; bh_mask) </code>
<CODE CLASS="Code">    do_bottom_half(  ); </code>
</pre>

<P CLASS="Body">Now comes the actual scheduling, and therefore a potential process switch.</p>


<P CLASS="Body">The value of <CODE CLASS="Literal">current</code> is saved in the <CODE CLASS="Literal">prev</code> local variable and the <CODE CLASS="Literal">need_resched</code> field of <CODE CLASS="Literal">prev</code> is set to 0. The key outcome of the function is to set another local variable called <CODE CLASS="Literal">next</code> so that it points to the descriptor of the process selected to replace <CODE CLASS="Literal">prev</code>.</p>


<P CLASS="Body">First, a check is made to determine whether <CODE CLASS="Literal">prev</code> is a Round Robin real-time process (<CODE CLASS="Literal">policy</code> field set to <CODE CLASS="Literal">SCHED_RR</code>) that has exhausted its quantum. If so, <CODE CLASS="Literal">schedule(  )</code> assigns a new quantum to <CODE CLASS="Literal">prev</code> and puts it at the bottom of the runqueue list: </p>

<PRE><CODE CLASS="Code">if (!prev-&gt;counter &amp;&amp; prev-&gt;policy == SCHED_RR) { </code>
<CODE CLASS="Code">    prev-&gt;counter = prev-&gt;priority; </code>
<CODE CLASS="Code">    move_last_runqueue(prev); </code>
<CODE CLASS="Code">} </code>
</pre>

<P CLASS="Body">Now <CODE CLASS="Literal">schedule(  )</code> examines the state of <CODE CLASS="Literal">prev</code>. If it has nonblocked pending signals and its state is <CODE CLASS="Literal">TASK_INTERRUPTIBLE</code>, the function wakes up the process as follows. This action is not the same as assigning the processor to <CODE CLASS="Literal">prev</code>; it just gives <CODE CLASS="Literal">prev</code> a chance to be selected for execution: </p>

<PRE><CODE CLASS="Code">if (prev-&gt;state == TASK_INTERRUPTIBLE &amp;&amp; </code>
<CODE CLASS="Code">    signal_pending(prev)) </code>
<CODE CLASS="Code">    prev-&gt;state = TASK_RUNNING; </code>
</pre>

<P CLASS="Body">If <CODE CLASS="Literal">prev</code> is not in the <CODE CLASS="Literal">TASK_RUNNING</code> state, <CODE CLASS="Literal">schedule(  )</code> was directly invoked by the process itself because it had to wait on some external resource; therefore, <CODE CLASS="Literal">prev</code> must be removed from the runqueue list: </p>

<PRE><CODE CLASS="Code">if (prev-&gt;state != TASK_RUNNING) </code>
<CODE CLASS="Code">    del_from_runqueue(prev); </code>
</pre>

<P CLASS="Body">Next, <CODE CLASS="Literal">schedule(  )</code> must select the process to be executed in the next time quantum. To that end, the function scans the runqueue list. It starts from the process referenced by the <CODE CLASS="Literal">next_run</code> field of <CODE CLASS="Literal">init_task</code>, which is the descriptor of process 0 (<EM CLASS="Emphasis">swapper</em>). The objective is to store in <CODE CLASS="Literal">next</code> the process descriptor pointer of the highest priority process. In order to do this, <CODE CLASS="Literal">next</code> is initialized to the first runnable process to be checked, and <CODE CLASS="Literal">c</code> is initialized to its &quot;goodness&quot; (see the later section "<A HREF="ch10.html#20825" CLASS="XRef">How Good Is a Runnable Process?</a>&quot;): </p>

<PRE><CODE CLASS="Code">if (prev-&gt;state == TASK_RUNNING) { </code>
<CODE CLASS="Code">    next = prev; </code>
<CODE CLASS="Code">    if (prev-&gt;policy &amp; SCHED_YIELD) { </code>
<CODE CLASS="Code">        prev-&gt;policy &amp;= &#126;SCHED_YIELD; </code>
<CODE CLASS="Code">        c = 0; </code>
<CODE CLASS="Code">    } else </code>
<CODE CLASS="Code">        c = goodness(prev, prev); </code>
<CODE CLASS="Code">} else { </code>
<CODE CLASS="Code">    c = -1000; </code>
<CODE CLASS="Code">    next = &amp;init_task; </code>
<CODE CLASS="Code">} </code>
</pre>

<P CLASS="Body">If the <CODE CLASS="Literal">SCHED_YIELD</code> flag of <CODE CLASS="Literal">prev-&gt;policy</code> is set, <CODE CLASS="Literal">prev</code> has voluntarily relinquished the CPU by issuing a <CODE CLASS="Literal">sched_ yield(  )</code> system call. In this case, the function assigns a zero goodness to it.</p>


<P CLASS="Body">Now <CODE CLASS="Literal">schedule(  )</code> repeatedly invokes the <CODE CLASS="Literal">goodness(  )</code> function on the runnable processes to determine the best candidate: </p>

<PRE><CODE CLASS="Code">p = init_task.next_run; </code>
<CODE CLASS="Code">while (p != &amp;init_task) { </code>
<CODE CLASS="Code">    weight = goodness(prev, p); </code>
<CODE CLASS="Code">    if (weight &gt; c) { </code>
<CODE CLASS="Code">        c = weight; </code>
<CODE CLASS="Code">        next = p; </code>
<CODE CLASS="Code">    } </code>
<CODE CLASS="Code">    p = p-&gt;next_run; </code>
<CODE CLASS="Code">} </code>
</pre>

<P CLASS="Body">The <CODE CLASS="Literal">while</code> loop selects the first process in the runqueue having maximum weight. If the previous process is runnable, it is preferred with respect to other runnable processes having the same weight.</p>


<P CLASS="Body">Notice that if the runqueue list is empty (no runnable process exists except for <EM CLASS="Emphasis">swapper</em>), the cycle is not entered and <CODE CLASS="Literal">next</code> points to <CODE CLASS="Literal">init_task</code>. Moreover, if all processes in the runqueue list have a priority lesser than or equal to the priority of <CODE CLASS="Literal">prev</code>, no process switch will take place and the old process will continue to be executed.</p>


<P CLASS="Body">A further check must be made at the exit of the loop to determine whether <CODE CLASS="Literal">c</code> is 0. This occurs only when all the processes in the runqueue list have exhausted their quantum, that is, all of them have a zero <CODE CLASS="Literal">counter</code> field. When this happens, a new epoch begins, therefore <CODE CLASS="Literal">schedule(  )</code> assigns to all existing processes (not only to the <CODE CLASS="Literal">TASK_RUNNING</code> ones) a fresh quantum, whose duration is the sum of the <CODE CLASS="Literal">priority</code> value plus half the <CODE CLASS="Literal">counter</code> value: </p>

<PRE><CODE CLASS="Code">if (!c) { </code>
<CODE CLASS="Code">    for_each_task(p) </code>
<CODE CLASS="Code">        p-&gt;counter = (p-&gt;counter &gt;&gt; 1) + p-&gt;priority; </code>
<CODE CLASS="Code">} </code>
</pre>

<P CLASS="Body">In this way, suspended or stopped processes have their dynamic priorities periodically increased. As stated earlier, the rationale for increasing the <CODE CLASS="Literal">counter</code> value of suspended or stopped processes is to give preference to I/O-bound processes. However, even after an infinite number of increases, the value of <CODE CLASS="Literal">counter</code> can never become larger than twice<A HREF="#footnote-3" TITLE="Footnote" CLASS="footnote">[3]</a> the <CODE CLASS="Literal">priority</code> value.</p>


<P CLASS="Body">Now comes the concluding part of <CODE CLASS="Literal">schedule(  )</code>: if a process other than <CODE CLASS="Literal">prev</code> has been selected, a process switch must take place. Before performing it, however, the <CODE CLASS="Literal">context_swtch</code> field of <CODE CLASS="Literal">kstat</code> is increased by 1 to update the statistics maintained by the kernel: </p>

<PRE><CODE CLASS="Code">if (prev != next) { </code>
<CODE CLASS="Code">    kstat.context_swtch++; </code>
<CODE CLASS="Code">    switch_to(prev,next); </code>
<CODE CLASS="Code">} </code>
<CODE CLASS="Code">return; </code>
</pre>

<P CLASS="Body">Notice that the <CODE CLASS="Literal">return</code> statement that exits from <CODE CLASS="Literal">schedule(  )</code> will not be performed right away by the <CODE CLASS="Literal">next</code> process but at a later time by the <CODE CLASS="Literal">prev</code> one when the scheduler selects it again for execution.</p>


<H3 CLASS="HeadB"><A NAME="20825"></a>How Good Is a Runnable Process?</h3>


<P CLASS="Body">The heart of the scheduling algorithm includes identifying the best candidate among all processes in the runqueue list. This is what the <CODE CLASS="Literal">goodness(  )</code> function does. It receives as input parameters <CODE CLASS="Literal">prev</code> (the descriptor pointer of the previously running process) and <CODE CLASS="Literal">p</code> (the descriptor pointer of the process to evaluate). The integer value <CODE CLASS="Literal">c</code> returned by <CODE CLASS="Literal">goodness(  )</code> measures the &quot;goodness&quot; of <CODE CLASS="Literal">p</code> and has the following meanings:</p>

<DL>
<DT CLASS="ListVariableTerm"><EM CLASS="Emphasis">c</em> = -1000 </dt>
<DD CLASS="ListVariable"><CODE CLASS="Literal">p</code> must never be selected; this value is returned when the runqueue list contains only <CODE CLASS="Literal">init_task</code>.</dd>
<p>
<DT CLASS="ListVariableTerm"><EM CLASS="Emphasis">c</em> = 0 </dt>
<DD CLASS="ListVariable"><CODE CLASS="Literal">p</code> has exhausted its quantum. Unless <CODE CLASS="Literal">p</code> is the first process in the runqueue list and all runnable processes have also exhausted their quantum, it will not be selected for execution.</dd>
<p>
<DT CLASS="ListVariableTerm">0 &lt; <EM CLASS="Emphasis">c</em> &lt; 1000 </dt>
<DD CLASS="ListVariable"><CODE CLASS="Literal">p</code> is a conventional process that has not exhausted its quantum; a higher value of <CODE CLASS="Literal">c</code> denotes a higher level of goodness.</dd>
<p>
<DT CLASS="ListVariableTerm"><EM CLASS="Emphasis">c</em> &gt;= 1000 </dt>
<DD CLASS="ListVariable"><CODE CLASS="Literal">p</code> is a real-time process; a higher value of <CODE CLASS="Literal">c</code> denotes a higher level of goodness.</dd>
<p>
</dl>

<P CLASS="Body">The <CODE CLASS="Literal">goodness(  )</code> function is equivalent to: </p>

<PRE><CODE CLASS="Code">if (p-&gt;policy != SCHED_OTHER) </code>
<CODE CLASS="Code">       return 1000 + p-&gt;rt_priority; </code>
<CODE CLASS="Code">if (p-&gt;counter == 0) </code>
<CODE CLASS="Code">       return 0; </code>
<CODE CLASS="Code">if (p-&gt;mm == prev-&gt;mm) </code>
<CODE CLASS="Code">       return p-&gt;counter + p-&gt;priority + 1; </code>
<CODE CLASS="Code">return p-&gt;counter + p-&gt;priority; </code>
</pre>

<P CLASS="Body">If the process is real-time, its goodness is set to at least 1000. If it is a conventional process that has exhausted its quantum, its goodness is set to 0; otherwise, it is set to <CODE CLASS="Literal">p-&gt;counter + p-&gt;priority</code>.</p>


<P CLASS="Body">A small bonus is given to <CODE CLASS="Literal">p</code> if it shares the address space with <CODE CLASS="Literal">prev</code> (i.e., if their process descriptors' <CODE CLASS="Literal">mm</code> fields point to the same memory descriptor). The rationale for this bonus is that if <CODE CLASS="Literal">p</code> runs right after <CODE CLASS="Literal">prev</code>, it will use the same page tables, hence the same memory; some of the valuable data may still be in the hardware cache.</p>


<H3 CLASS="HeadB">The Linux/SMP Scheduler</h3>


<P CLASS="Body">The Linux scheduler must be slightly modified in order to support the symmetric multiprocessor (SMP) architecture. Actually, each processor runs the <CODE CLASS="Literal">schedule(  )</code> function on its own, but processors must exchange information in order to boost system performance.</p>


<P CLASS="Body">When the scheduler computes the goodness of a runnable process, it should consider whether that process was previously running on the same CPU or on another one. A process that was running on the same CPU is always preferred, since the hardware cache of the CPU could still include useful data. This rule helps in reducing the number of cache misses.</p>


<P CLASS="Body">Let us suppose, however, that CPU 1 is running a process when a second, higher-priority process that was last running on CPU 2 becomes runnable. Now the kernel is faced with an interesting dilemma: should it immediately execute the higher-priority process on CPU 1, or should it defer that process's execution until CPU 2 becomes available? In the former case, hardware caches contents are discarded; in the latter case, parallelism of the SMP architecture may not be fully exploited when CPU 2 is running the idle process (<EM CLASS="Emphasis">swapper</em>).</p>


<P CLASS="Body">In order to achieve good system performance, Linux/SMP adopts an empirical rule to solve the dilemma. The adopted choice is always a compromise, and the trade-off mainly depends on the size of the hardware caches integrated into each CPU: the larger the CPU cache is, the more convenient it is to keep a process bound on that CPU.</p>


<H4 CLASS="HeadC">Linux/SMP scheduler data structures</h4>


<P CLASS="Body">An <CODE CLASS="Literal">aligned_data</code> table includes one data structure for each processor, which is used mainly to obtain the descriptors of current processes quickly. Each element is filled by every invocation of the <CODE CLASS="Literal">schedule(  )</code> function and has the following structure: </p>

<PRE><CODE CLASS="Code">struct schedule_data { </code>
<CODE CLASS="Code">    struct task_struct * curr; </code>
<CODE CLASS="Code">    unsigned long last_schedule; </code>
<CODE CLASS="Code">}; </code>
</pre>

<P CLASS="Body">The <CODE CLASS="Literal">curr</code> field points to the descriptor of the process running on the corresponding CPU, while <CODE CLASS="Literal">last_schedule</code> specifies when <CODE CLASS="Literal">schedule(  )</code> selected <CODE CLASS="Literal">curr</code> as the running process.</p>


<P CLASS="Body">Several SMP-related fields are included in the process descriptor. In particular, the <CODE CLASS="Literal">avg_slice</code> field keeps track of the average quantum duration of the process, and the <CODE CLASS="Literal">processor</code> field stores the logical identifier of the last CPU that executed it.</p>


<P CLASS="Body">The <CODE CLASS="Literal">cacheflush_time</code> variable contains a rough estimate of the minimal number of CPU cycles it takes to entirely overwrite the hardware cache content. It is initialized by the <CODE CLASS="Literal">smp_tune_scheduling(  )</code> function to:</p>

<center>
<P CLASS="EquationHolder"><IMG SRC="eqch1.gif" ALIGN="BASELINE">
&nbsp;</p>
</center>

<P CLASS="Body">Intel Pentium processors have a hardware cache of 8 KB, so their <CODE CLASS="Literal">cacheflush_time</code> is initialized to a few hundred CPU cycles, that is, a few microseconds. Recent Intel processors have larger hardware caches, and therefore the minimal cache flush time could range from 50 to 100 microseconds.</p>


<P CLASS="Body">As we shall see later, if <CODE CLASS="Literal">cacheflush_time</code> is greater than the average time slice of some currently running process, no process preemption is performed because it is convenient in this case to bind processes to the processors that last executed them.</p>


<H4 CLASS="HeadC"><A NAME="67967"></a>The schedule(  ) function</h4>


<P CLASS="Body">When the <CODE CLASS="Literal">schedule(  )</code> function is executed on an SMP system, it carries out the following operations:</p>

<OL>
<LI CLASS="ListNumber">Performs the initial part of <CODE CLASS="Literal">schedule(  )</code> as usual.</li>
<p>
<LI CLASS="ListNumber">Stores the logical identifier of the executing processor in the <CODE CLASS="Literal">this_cpu</code> local variable; such value is read from the <CODE CLASS="Literal">processor</code> field of <CODE CLASS="Literal">prev</code> (that is, of the process to be replaced).</li>
<p>
<LI CLASS="ListNumber">Initializes the <CODE CLASS="Literal">sched_data</code> local variable so that it points to the <CODE CLASS="Literal">schedule_data</code> structure of the <CODE CLASS="Literal">this_cpu</code> CPU.</li>
<p>
<LI CLASS="ListNumber">Invokes <CODE CLASS="Literal">goodness(  )</code> repeatedly to select the new process to be executed; this function also examines the <CODE CLASS="Literal">processor</code> field of the processes and gives a consistent bonus (<CODE CLASS="Literal">PROC_CHANGE_PENALTY</code>, usually 15) to the process that was last executed on the <CODE CLASS="Literal">this_cpu</code> CPU.</li>
<p>
<LI CLASS="ListNumber">If needed, recomputes process dynamic priorities as usual.</li>
<p>
<LI CLASS="ListNumber">Sets <CODE CLASS="Literal">sched_data-&gt;curr</code> to <CODE CLASS="Literal">next</code>.</li>
<p>
<LI CLASS="ListNumber">Sets <CODE CLASS="Literal">next-&gt;has_cpu</code> to 1 and <CODE CLASS="Literal">next-&gt;processor</code> to <CODE CLASS="Literal">this_cpu</code>.</li>
<p>
<LI CLASS="ListNumber">Stores the current Time Stamp Counter value in the <CODE CLASS="Literal">t</code> local variable.</li>
<p>
<LI CLASS="ListNumber">Stores the last time slice duration of <CODE CLASS="Literal">prev</code> in the <CODE CLASS="Literal">this_slice</code> local variable; this value is the difference between <CODE CLASS="Literal">t</code> and <CODE CLASS="Literal">sched_data-&gt;last_schedule</code>.</li>
<p>
<LI CLASS="ListNumber">Sets <CODE CLASS="Literal">sched_data-&gt;last_schedule</code> to <CODE CLASS="Literal">t</code>.</li>
<p>
<LI CLASS="ListNumber">Sets the <CODE CLASS="Literal">avg_slice</code> field of <CODE CLASS="Literal">prev</code> to (<CODE CLASS="Literal">prev-&gt;avg_slice+this_slice</code>)/2; in other words, updates the average.</li>
<p>
<LI CLASS="ListNumber">Performs the context switch.</li>
<p>
<LI CLASS="ListNumber">When the kernel returns here, the original previous process has been selected again by the scheduler; the <CODE CLASS="Literal">prev</code> local variable now refers to the process that has just been replaced. If <CODE CLASS="Literal">prev</code> is still runnable and it is not the idle task of this CPU, invokes the <CODE CLASS="Literal">reschedule_idle(  )</code> function on it (see the next section).</li>
<p>
<LI CLASS="ListNumber">Sets the <CODE CLASS="Literal">has_cpu</code> field of <CODE CLASS="Literal">prev</code> to 0.</li>
<p>
</ol>

<H4 CLASS="HeadC">The reschedule_idle(  ) function</h4>


<P CLASS="Body">The <CODE CLASS="Literal">reschedule_idle(  )</code> <CODE CLASS="Literal"></code>function is invoked when a process <CODE CLASS="Literal">p</code> becomes runnable (see the earlier section "<A HREF="ch10.html#57373" CLASS="XRef">The schedule(  ) Function</a>&quot;). On an SMP system, the function determines whether the process should preempt the current process of some CPU. It performs the following operations:</p>

<OL>
<LI CLASS="ListNumber">If <CODE CLASS="Literal">p</code> is a real-time process, always attempts to perform preemption: go to step 3.</li>
<p>
<LI CLASS="ListNumber">Returns immediately (does not attempt to preempt) if there is a CPU whose current process satisfies both of the following conditions:<A HREF="#footnote-4" TITLE="Footnote" CLASS="footnote">[4]</a></li>
<p>
<ul>
<LI CLASS="FM-ListBullet"><CODE CLASS="Literal">cacheflush_time</code> is greater than the average time slice of the current process. If this is true, the process is not dirtying the cache significantly.</li>
<p>
<LI CLASS="FM-ListBullet">Both <CODE CLASS="Literal">p</code> and the current process need the global kernel lock (see the section &quot;Global and Local Kernel Locks&quot; in Chapter 11) in order to access some critical kernel data structure. This check is performed because replacing a process holding the lock with another one that needs it is not fruitful.</li>
</ul>
<p>
<LI CLASS="ListNumber">If the <CODE CLASS="Literal">p-&gt;processor</code> CPU (the one on which <CODE CLASS="Literal">p</code> was last running) is idle, selects it.</li>
<p>
<LI CLASS="ListNumber">Otherwise, computes the difference:</li>
<p>

<P CLASS="EquationHolder"><CODE CLASS="Literal">goodness(tsk, p) - goodness(tsk, tsk)</code></p>

<P CLASS="ListNumber-">for each task <CODE CLASS="Literal">tsk</code> running on some CPU and selects the CPU for which the difference is greatest, provided it is a positive value. </p>

<LI CLASS="ListNumber">If CPU has been selected, sets the <CODE CLASS="Literal">need_resched</code> field of the corresponding running process and sends a &quot;reschedule&quot; message to that processor <CODE CLASS="Literal"></code>(see the section &quot;Interprocessor Interrupts&quot; in Chapter 11).</li>
<p>
</ol>
<p>

<H3 CLASS="HeadB"><A NAME="39073"></a>	Performance of the Scheduling Algorithm</h3>


<P CLASS="Body">The scheduling algorithm of Linux is both self-contained and relatively easy to follow. For that reason, many kernel hackers love to try to make improvements. However, the scheduler is a rather mysterious component of the kernel. While you can change its performance significantly by modifying just a few key parameters, there is usually no theoretical support to justify the results obtained. Furthermore, you can't be sure that the positive (or negative) results obtained will continue to hold when the mix of requests submitted by the users (real-time, interactive, I/O-bound, background, etc.) varies significantly. Actually, for almost every proposed scheduling strategy, it is possible to derive an artificial mix of requests that yields poor system performances.</p>


<P CLASS="Body">Let us try to outline some pitfalls of the Linux scheduler. As it will turn out, some of these limitations become significant on large systems with many users. On a single workstation that is running a few tens of processes at a time, the Linux scheduler is quite efficient. Since Linux was born on an Intel 80386 and continues to be most popular in the PC world, we consider the current Linux scheduler quite appropriate.</p>


<H4 CLASS="HeadC">The algorithm does not scale well</h4>


<P CLASS="Body">If the number of existing processes is very large, it is inefficient to recompute all dynamic priorities at once.</p>


<P CLASS="Body">In old traditional Unix kernels, the dynamic priorities were recomputed every second, thus the problem was even worse. Linux tries instead to minimize the overhead of the scheduler. Priorities are recomputed only when all runnable processes have exhausted their time quantum. Therefore, when the number of processes is large, the recomputation phase is more expensive but is executed less frequently.</p>


<P CLASS="Body">This simple approach has the disadvantage that when the number of runnable processes is very large, I/O-bound processes are seldom boosted, and therefore interactive applications have a longer response time.</p>


<H4 CLASS="HeadC">The predefined quantum is too large for high system loads</h4>


<P CLASS="Body">The system responsiveness experienced by users depends heavily on the <EM CLASS="Emphasis">system load</em>, which is the average number of processes that are runnable, and hence waiting for CPU time.<A HREF="#footnote-5" TITLE="Footnote" CLASS="footnote">[5]</a></p>


<P CLASS="Body">As mentioned before, system responsiveness depends also on the average time-quantum duration of the runnable processes. In Linux, the predefined time quantum appears to be too large for high-end machines having a very high expected system load.</p>


<H4 CLASS="HeadC">I/O-bound process boosting strategy is not optimal</h4>


<P CLASS="Body">The preference for I/O-bound processes is a good strategy to ensure a short response time for interactive programs, but it is not perfect. Indeed, some batch programs with almost no user interaction are I/O-bound. For instance, consider a database search engine that must typically read lots of data from the hard disk or a network application that must collect data from a remote host on a slow link. Even if these kinds of processes do not need a short response time, they are boosted by the scheduling algorithm.</p>


<P CLASS="Body">On the other hand, interactive programs that are also CPU-bound may appear unresponsive to the users, since the increment of dynamic priority due to I/O blocking operations may not compensate for the decrement due to CPU usage.</p>


<H4 CLASS="HeadC">Support for real-time applications is weak</h4>


<P CLASS="Body">As stated in the first chapter, nonpreemptive kernels are not well suited for real-time applications, since processes may spend several milliseconds in Kernel Mode while handling an interrupt or exception. During this time, a real-time process that becomes runnable cannot be resumed. This is unacceptable for real-time applications, which require predictable and low response times.<A HREF="#footnote-6" TITLE="Footnote" CLASS="footnote">[6]</a></p>


<P CLASS="Body">Future versions of Linux will likely address this problem, either by implementing SVR4's &quot;fixed preemption points&quot; or by making the kernel fully preemptive.</p>


<P CLASS="Body">However, kernel preemption is just one of several necessary conditions for implementing an effective real-time scheduler. Several other issues must be considered. For instance, real-time processes often must use resources also needed by conventional processes. A real-time process may thus end up waiting until a lower-priority process releases some resource. This phenomenon is called <EM CLASS="Emphasis">priority inversion</em>. Moreover, a real-time process could require a kernel service that is granted on behalf of another lower-priority process (for example, a kernel thread). This phenomenon is called <EM CLASS="Emphasis">hidden scheduling</em>. An effective real-time scheduler should address and resolve such problems.</p>


<H2 CLASS="HeadA"><A NAME="77170"></a>System Calls Related to Scheduling</h2>


<P CLASS="Body">Several system calls have been introduced to allow processes to change their priorities and scheduling policies. As a general rule, users are always allowed to lower the priorities of their processes. However, if they want to modify the priorities of processes belonging to some other user or if they want to increase the priorities of their own processes, they must have superuser privileges.</p>


<H3 CLASS="HeadB">The nice(  ) System Call</h3>


<P CLASS="Body">The <CODE CLASS="Literal">nice(  )<A HREF="#footnote-7" TITLE="Footnote" CLASS="footnote">[7]</a></code> system call allows processes to change their base priority. The integer value contained in the <CODE CLASS="Literal">increment</code> parameter is used to modify the <CODE CLASS="Literal">priority</code> field of the process descriptor. The <CODE CLASS="Literal">nice</code> Unix command, which allows users to run programs with modified scheduling priority, is based on this system call.</p>


<P CLASS="Body">The <CODE CLASS="Literal">sys_nice(  )</code> service routine handles the <CODE CLASS="Literal">nice(  )</code> system call. Although the <CODE CLASS="Literal">increment</code> parameter may have any value, absolute values larger than 40 are trimmed down to 40. Traditionally, negative values correspond to requests for priority increments and require superuser privileges, while positive ones correspond to requests for priority decrements.</p>


<P CLASS="Body">The function starts by copying the value of <CODE CLASS="Literal">increment</code> into the <CODE CLASS="Literal">newprio</code> local variable. In the case of a negative increment, the function invokes the <CODE CLASS="Literal">capable(  )</code> function to verify whether the process has a <CODE CLASS="Literal">CAP_SYS_NICE</code> capability. We shall discuss that function, together with the notion of capability, in <EM CLASS="EmphasisRoman">Chapter 19, </em><CITE CLASS="Citation">Program Execution</cite>. If the user turns out to have the capability required to change priorities, <CODE CLASS="Literal">sys_nice(  ) </code>changes the sign of <CODE CLASS="Literal">newprio</code> and it sets the <CODE CLASS="Literal">increase</code> local flag: </p>

<PRE><CODE CLASS="Code">increase = 0 </code>
<CODE CLASS="Code">newprio = increment; </code>
<CODE CLASS="Code">if (increment &lt; 0) { </code>
<CODE CLASS="Code">    if (!capable(CAP_SYS_NICE)) </code>
<CODE CLASS="Code">        return -EPERM; </code>
<CODE CLASS="Code">    newprio = -increment; </code>
<CODE CLASS="Code">    increase = 1; </code>
<CODE CLASS="Code">} </code>
</pre>

<P CLASS="Body">If <CODE CLASS="Literal">newprio</code> has a value larger than 40, the function trims it down to 40. At this point, the <CODE CLASS="Literal">newprio</code> local variable may have any value included from 0 to 40, inclusive. The value is then converted according to the priority scale used by the scheduling algorithm. Since the highest base priority allowed is 2 <EM CLASS="Symbol">&#215; </em><CODE CLASS="Literal">DEF_PRIORITY</code>, the new value is:</p>

<center>
<P CLASS="EquationHolder"><IMG SRC="eqch3.gif" ALIGN="BASELINE">
&nbsp;</p>
</center>

<P CLASS="Body">The resulting value is copied into <CODE CLASS="Literal">increment</code> with the proper sign: </p>

<PRE><CODE CLASS="Code">if (newprio &gt; 40) </code>
<CODE CLASS="Code">    newprio = 40; </code>
<CODE CLASS="Code">newprio = (newprio * DEF_PRIORITY + 10) / 20; </code>
<CODE CLASS="Code">increment = newprio; </code>
<CODE CLASS="Code">if (increase) </code>
<CODE CLASS="Code">    increment = -increment; </code>
</pre>

<P CLASS="Body">Since <CODE CLASS="Literal">newprio</code> is an integer variable, the expression in the code is equivalent to the formula shown earlier.</p>


<P CLASS="Body">The function then sets the final value of <CODE CLASS="Literal">priority</code> by subtracting the value of <CODE CLASS="Literal">increment</code> from it. However, the final base priority of the process cannot be smaller than 1 or larger than 2 <EM CLASS="Symbol">&#215; </em><CODE CLASS="Literal">DEF_PRIORITY</code>: </p>

<PRE><CODE CLASS="Code">if (current-&gt;priority - increment &lt; 1) </code>
<CODE CLASS="Code">    current-&gt;priority = 1; </code>
<CODE CLASS="Code">else if (current-&gt;priority &gt; DEF_PRIORITY*2) </code>
<CODE CLASS="Code">    current-&gt;priority = DEF_PRIORITY*2; </code>
<CODE CLASS="Code">else </code>
<CODE CLASS="Code">    current-&gt;priority -= increment; </code>
<CODE CLASS="Code">return 0; </code>
</pre>

<P CLASS="Body">A <CODE CLASS="Literal">niced</code> process changes over time like any other process, getting extra priority if necessary or dropping back in deference to other <CODE CLASS="Literal"></code>processes.</p>


<H3 CLASS="HeadB">The getpriority(  ) and setpriority(  ) System Calls</h3>


<P CLASS="Body">The <CODE CLASS="Literal">nice(  )</code> system call affects only the process that invokes it. Two other system calls, denoted as <CODE CLASS="Literal">getpriority(  )</code> and <CODE CLASS="Literal">setpriority(  )</code>, act on the base priorities of all processes in a given group. <CODE CLASS="Literal">getpriority(  )</code> returns 20 plus the highest base priority among all processes in a given group; <CODE CLASS="Literal">setpriority(  )</code> sets the base priority of all processes in a given group to a given value.</p>


<P CLASS="Body">The kernel implements these system calls by means of the <CODE CLASS="Literal">sys_getpriority(  )</code> and <CODE CLASS="Literal">sys_setpriority(  )</code> service routines. Both of them act essentially on the same group of parameters:</p>

<DL>
<DT CLASS="ListVariableTerm"><CODE CLASS="Literal">which</code> </dt>
<DD CLASS="ListVariable">Identifies the group of processes; it can assume one of the following values:</dd>
<p>
<DT CLASS="FM-ListVariableTerm"><CODE CLASS="Literal">PRIO_PROCESS</code> </dt>
<DD CLASS="FM-ListVariable">Select the processes according to their process ID (<CODE CLASS="Literal">pid</code> field of the process descriptor).</dd>
<p>
<DT CLASS="FM-ListVariableTerm"><CODE CLASS="Literal">PRIO_PGRP</code> </dt>
<DD CLASS="FM-ListVariable">Select the processes according to their group ID (<CODE CLASS="Literal">pgrp</code> field of the process descriptor).</dd>
<p>
<DT CLASS="FM-ListVariableTerm"><CODE CLASS="Literal">PRIO_USER</code> </dt>
<DD CLASS="FM-ListVariable">Select the processes according to their user ID (<CODE CLASS="Literal">uid</code> field of the process descriptor).</dd>
<p>
<DT CLASS="ListVariableTerm"><CODE CLASS="Literal">who</code> </dt>
<DD CLASS="ListVariable">Value of the <CODE CLASS="Literal">pid</code>, <CODE CLASS="Literal">pgrp</code>, or <CODE CLASS="Literal">uid</code> field (depending on the value of <CODE CLASS="Literal">which</code>) to be used for selecting the processes. If <CODE CLASS="Literal">who</code> is 0, its value is set to that of the corresponding field of the <CODE CLASS="Literal">current</code> process.</dd>
<p>
<DT CLASS="ListVariableTerm"><CODE CLASS="Literal">niceval</code> </dt>
<DD CLASS="ListVariable">The new base priority value (needed only by <CODE CLASS="Literal">sys_setpriority(  )</code>). It should range between -20 (highest priority) and +20 (minimum priority).</dd>
<p>
</dl>

<P CLASS="Body">As stated before, only processes with a <CODE CLASS="Literal">CAP_SYS_NICE</code> capability are allowed to increase their own base priority or to modify that of other processes.</p>


<P CLASS="Body">As we have seen in Chapter 8, system calls return a negative value only if some error occurred. For that reason, <CODE CLASS="Literal">getpriority(  )</code> does not return a normal nice value ranging between -20 and 20, but rather a nonnegative value ranging between 0 and 40.</p>


<H3 CLASS="HeadB"><A NAME="40766"></a>System Calls Related to Real-Time Processes</h3>


<P CLASS="Body">We now introduce a group of system calls that allow processes to change their scheduling discipline and, in particular, to become real-time processes. As usual, a process must have a <CODE CLASS="Literal">CAP_SYS_NICE</code> capability in order to modify the values of the <CODE CLASS="Literal">rt_priority</code> and <CODE CLASS="Literal">policy</code> process descriptor fields of any process, including itself.</p>


<H4 CLASS="HeadC">The sched_getscheduler(  ) and sched_setscheduler(  ) system calls</h4>


<P CLASS="Body">The <CODE CLASS="Literal">sched_ getscheduler(  )</code> system call queries the scheduling policy currently applied to the process identified by the <CODE CLASS="Literal">pid</code> parameter. If <CODE CLASS="Literal">pid</code> equals 0, the policy of the calling process will be retrieved. On success, the system call returns the policy for the process: <CODE CLASS="Literal">SCHED_FIFO</code>, <CODE CLASS="Literal">SCHED_RR</code>, or <CODE CLASS="Literal">SCHED_OTHER</code>. The corresponding <CODE CLASS="Literal">sys_sched_getscheduler(  )</code> service routine invokes <CODE CLASS="Literal">find_task_by_pid(  )</code>, which locates the process descriptor corresponding to the given <CODE CLASS="Literal">pid</code> and returns the value of its <CODE CLASS="Literal">policy</code> field.</p>


<P CLASS="Body">The <CODE CLASS="Literal">sched_setscheduler(  )</code> system call sets both the scheduling policy and the associated parameters for the process identified by the parameter <CODE CLASS="Literal">pid</code>. If <CODE CLASS="Literal">pid</code> is equal to 0, the scheduler parameters of the calling process will be set.</p>


<P CLASS="Body">The corresponding <CODE CLASS="Literal">sys_sched_setscheduler(  )</code> function checks whether the scheduling policy specified by the <CODE CLASS="Literal">policy</code> parameter and the new static priority specified by the <CODE CLASS="Literal">param-&gt;sched_priority</code> parameter are valid. It also checks whether the process has <CODE CLASS="Literal">CAP_SYS_NICE</code> capability or whether its owner has superuser rights. If everything is OK, it executes the following statements: </p>

<PRE><CODE CLASS="Code">p-&gt;policy = policy; </code>
<CODE CLASS="Code">p-&gt;rt_priority = param-&gt;sched_priority; </code>
<CODE CLASS="Code">if (p-&gt;next_run) </code>
<CODE CLASS="Code">    move_first_runqueue(p); </code>
<CODE CLASS="Code">current-&gt;need_resched = 1; </code>
</pre>

<H4 CLASS="HeadC">The sched_ getparam(  ) and sched_setparam(  ) system calls</h4>


<P CLASS="Body">The <CODE CLASS="Literal">sched_getparam(  )</code> system call retrieves the scheduling parameters for the process identified by <CODE CLASS="Literal">pid</code>. If <CODE CLASS="Literal">pid</code> is 0, the parameters of the <CODE CLASS="Literal">current</code> process are retrieved. The corresponding <CODE CLASS="Literal">sys_sched_getparam(  )</code> service routine, as one would expect, finds the process descriptor pointer associated with <CODE CLASS="Literal">pid</code>, stores its <CODE CLASS="Literal">rt_priority</code> field in a local variable of type <CODE CLASS="Literal">sched_param</code>, and invokes <CODE CLASS="Literal">copy_to_user(  )</code> to copy it into the process address space at the address specified by the <CODE CLASS="Literal">param</code> parameter.</p>


<P CLASS="Body">The <CODE CLASS="Literal">sched_setparam(  )</code> system call is similar to <CODE CLASS="Literal">sched_setscheduler(  )</code>: it differs from the latter by not letting the caller set the <CODE CLASS="Literal">policy</code> field's value.<A HREF="#footnote-8" TITLE="Footnote" CLASS="footnote">[8]</a> The corresponding <CODE CLASS="Literal">sys_sched_setparam(  )</code> service routine is almost identical to <CODE CLASS="Literal">sys_sched_setscheduler(  )</code>, but the policy of the affected process is never changed.</p>


<H4 CLASS="HeadC">The sched_ yield(  ) system call</h4>


<P CLASS="Body">The <CODE CLASS="Literal">sched_ yield(  )</code> system call allows a process to relinquish the CPU voluntarily without being suspended; the process remains in a <CODE CLASS="Literal">TASK_RUNNING</code> state, but the scheduler puts it at the end of the runqueue list. In this way, other processes having the same dynamic priority will have a chance to run. The call is used mainly by <CODE CLASS="Literal">SCHED_FIFO</code> processes.</p>


<P CLASS="Body">The corresponding <CODE CLASS="Literal">sys_sched_ yield(  )</code> service routine executes these statements: </p>

<PRE><CODE CLASS="Code">if (current-&gt;policy == SCHED_OTHER) </code>
<CODE CLASS="Code">    current-&gt;policy |= SCHED_YIELD; </code>
<CODE CLASS="Code">current-&gt;need_resched = 1; </code>
<CODE CLASS="Code">move_last_runqueue(current); </code>
</pre>

<P CLASS="Body">Notice that the <CODE CLASS="Literal">SCHED_YIELD</code> field is set in the <CODE CLASS="Literal">policy</code> field of the process descriptor only if the process is a conventional <CODE CLASS="Literal">SCHED_OTHER</code> process. As a result, the next invocation of <CODE CLASS="Literal">schedule(  )</code> will view this process as one that has exhausted its time quantum (see how <CODE CLASS="Literal">schedule(  )</code> handles the <CODE CLASS="Literal">SCHED_YIELD</code> field).</p>


<H4 CLASS="HeadC">The sched_ get_priority_min(  ) and sched_ get_priority_max(  ) system calls</h4>


<P CLASS="Body">The <CODE CLASS="Literal">sched_get_priority_min(  )</code> and <CODE CLASS="Literal">sched_get_priority_max(  )</code> system calls return, respectively, the minimum and the maximum real-time static priority value that can be used with the scheduling policy identified by the <CODE CLASS="Literal">policy</code> parameter.</p>


<P CLASS="Body">The <CODE CLASS="Literal">sys_sched_get_priority_min(  )</code> service routine returns 1 if <CODE CLASS="Literal">current</code> is a real-time process, 0 otherwise.</p>


<P CLASS="Body">The <CODE CLASS="Literal">sys_sched_get_priority_max(  )</code> service routine returns 99 (the highest priority) if <CODE CLASS="Literal">current</code> is a real-time process, 0 otherwise.</p>


<H4 CLASS="HeadC">The sched_rr_ get_interval(  ) system call</h4>


<P CLASS="Body">The <CODE CLASS="Literal">sched_rr_get_interval(  )</code> system call should get the round robin time quantum for the named real-time process.</p>


<P CLASS="Body">The corresponding <CODE CLASS="Literal">sys_sched_rr_get_interval(  )</code> service routine does not operate as expected, since it always returns a 150-millisecond value in the <CODE CLASS="Literal">timespec</code> structure pointed to by <CODE CLASS="Literal">tp</code>. This system call remains effectively unimplemented in Linux.</p>


<H2 CLASS="HeadA">Anticipating Linux 2.4</h2>


<P CLASS="Body">Linux 2.4 introduces a subtle optimization concerning TLB flushing for kernel threads and zombie processes. As a result, the active Page Global Directory is set by the <CODE CLASS="Literal">schedule(  )</code> function rather than by the <CODE CLASS="Literal">switch_to</code> macro.</p>


<P CLASS="Body">The Linux 2.4 scheduling algorithm for SMP machines has been improved and simplified. Whenever a new process becomes runnable, the kernel checks whether the preferred CPU of the process, that is, the CPU on which it was last running, is idle; in this case, the kernel assigns the process to that CPU. Otherwise, the kernel assigns the process to another idle CPU, if any. If all CPUs are busy, the kernel checks whether the process has enough priority to preempt the process running on the preferred CPU. If not, the kernel tries to preempt some other CPU only if the new runnable process is real-time or if it has short average time slices compared to the hardware cache rewriting time. (Roughly, preemption occurs if the new runnable process is interactive and the preferred CPU will not reschedule shortly.) </p>

<HR>

<P CLASS="Footnote"><A NAME="footnote-1"></a>1.
Recall that stopped and suspended processes cannot be selected by the scheduling algorithm to run on the CPU.</p>


<P CLASS="Footnote"><A NAME="footnote-2"></a>2.
Actually, things could be much worse than this; for example, if the time required for task switch is counted in the process quantum, all CPU time will be devoted to task switch and no process can progress toward its termination. Anyway, you got the point.</p>


<P CLASS="Footnote"><A NAME="footnote-3"></a>3.
Assume both <CODE CLASS="Literal">priority </code>and <CODE CLASS="Literal">counter </code>equal to P; then the geometric series <EM CLASS="Emphasis">P </em><EM CLASS="Symbol">&#215; </em>(1 + <EM CLASS="Superscript">1</em><EM CLASS="Subscript">/2</em> + <EM CLASS="Superscript">1</em><EM CLASS="Subscript">/4</em> + <EM CLASS="Superscript">1</em><EM CLASS="Subscript">/8</em> +  . . .  ) converges to 2 <EM CLASS="Symbol">&#215;</em><EM CLASS="Emphasis">P</em>.</p>


<P CLASS="Footnote"><A NAME="footnote-4"></a>4.
These conditions look like voodoo magic; perhaps, they are empirical rules that make the SMP scheduler work better.</p>


<P CLASS="Footnote"><A NAME="footnote-5"></a>5.
The <CODE CLASS="Literal">uptime </code>program returns the system load for the past 1, 5, and 15 minutes. The same information can be obtained by reading the <EM CLASS="Emphasis">/proc/loadavg</em><CODE CLASS="Literal"> </code>file.</p>


<P CLASS="Footnote"><A NAME="footnote-6"></a>6.
The Linux kernel has been modified in several ways so it can handle a few hard real-time jobs if they remain short. Basically, hardware interrupts are trapped and kernel execution is monitored by a kind of &quot;superkernel.&quot; These changes do not make Linux a true real-time system, though.</p>


<P CLASS="Footnote"><A NAME="footnote-7"></a>7.
Since this system call is usually invoked to lower the priority of a process, users who invoke it for their processes are &quot;nice&quot; toward other users.</p>


<P CLASS="Footnote"><A NAME="footnote-8"></a>8.
This anomaly is caused by a specific requirement of the POSIX standard.</p>



</blockquote>


<!-- End of sample chapter -->
<p><b>Back to: <a href="../noframes.html">Understanding the Linux Kernel</a></b>

<!-- O'Reilly Footer Begins Here -->

<CENTER>
<HR SIZE="1" NOSHADE>
<FONT SIZE="1" FACE="Verdana, Arial, Helvetica">
<A HREF="http://www.oreilly.com/">
<B>O'Reilly&nbsp;Home</B></A> <B> | </B>
<A HREF="http://www.oreilly.com/sales/bookstores">
<B>O'Reilly&nbsp;Bookstores</B></A> <B> | </B>
<A HREF="http://www.oreilly.com/order_new/">
<B>How&nbsp;to&nbsp;Order</B></A> <B> | </B>
<A HREF="http://www.oreilly.com/oreilly/contact.html">
<B>O'Reilly&nbsp;Contacts<BR></B></A>
<A HREF="http://www.oreilly.com/international/">
<B>International</B></A> <B> | </B>
<A HREF="http://www.oreilly.com/oreilly/about.html">
<B>About&nbsp;O'Reilly</B></A> <B> | </B>
<A HREF="http://www.oreilly.com/affiliates.html">
<B>Affiliated&nbsp;Companies</B></A><p>
<EM>&copy; 2000, O'Reilly &amp; Associates, Inc.</EM><BR>
<A HREF="mailto:webmaster@oreilly.com"><I>webmaster@oreilly.com</I></A>
</FONT>
</CENTER>

<!-- O'Reilly Footer Ends Here -->

</BODY>
</html>
